---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 
```{r}
#install.packages("corrplot")
#install.packages("Rfast")
#install.packages("phyloseq")
#install.packages("glmnet")
#install.packages("randcorr")
install.packages("hrbrthemes")
library(randcorr)
library(ggplot2)
library(hrbrthemes)
library(glmnet)
library(Rfast)
library(corrplot)
```


```{r}
# 1a
create_TC = function(interval, one_time, start_time){
  
  # Create initial matrix
  TC = matrix(0, 240, 1)
  
  # Counts for how many ones have been added / not added
  on_count = 1
  off_count = 0
  
  for(i in 1:240){
    
    # Check if the current time in source is before our start time
    if (i <= start_time) {
      next
    }
    
    # Change value in matrix if it is within the time period to do so 
    # Otherwise increment the time that one has not been added
    # Reset if at the end of a interval
    if(on_count <= one_time) {
      TC[i] = 1
      on_count = on_count + 1
    } else{
      off_count = off_count + 1
      if (off_count == interval - one_time) {
        on_count = 1
        off_count = 0
      }
  
    }
  
  }
  return(TC)
}
```


```{r}
# 1a
TC1 = create_TC(30, 15, 0)
TC2 = create_TC(45, 20, 20)
TC3 = create_TC(60, 25, 0)
TC4 = create_TC(40, 15, 0)
TC5 = create_TC(40, 20, 0)
TC6 = create_TC(40, 25, 0)

```

```{r}
# 1a
#standardise_TC = function(TC) {
#  TC_mean = mean(TC)
#  TC_var = var(TC)
#  TC1 = TC - TC_mean
#  TC2 = TC1 / sqrt(TC_var[1])
#  return(TC2)
#}
```





Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```{r}
# 1a
standard_TC1 = scale(TC1)
standard_TC2 = scale(TC2)
standard_TC3 = scale(TC3)
standard_TC4 = scale(TC4)
standard_TC5 = scale(TC5)
standard_TC6 = scale(TC6)
full_TC = matrix(c(standard_TC1, standard_TC2, standard_TC3, standard_TC4, standard_TC5, standard_TC6), 240, 6)
#full_TC2 = matrix(c(TC1, TC2, TC3, TC4, TC5, TC6), 240, 6)
#full_TC2 = scale(full_TC)

normalised_TC1 = sqrt(sum(TC1^2))
normalised_TC2 = sqrt(sum(TC2^2))
normalised_TC3 = sqrt(sum(TC3^2))
normalised_TC4 = sqrt(sum(TC4^2))
normalised_TC5 = sqrt(sum(TC5^2))
normalised_TC6 = sqrt(sum(TC6^2))

TC1 / normalised_TC1
TC6 / normalised_TC6
```


```{r}
# 1a

plot(full_TC[1:nrow(full_TC), 1], ylab = "Temporal source 1", pch = 1, type = "line")
plot(full_TC[1:nrow(full_TC), 2], ylab = "Temporal source 2", pch = 1, type = "line")
plot(full_TC[1:nrow(full_TC), 3], ylab = "Temporal source 3", pch = 1, type = "line")
plot(full_TC[1:nrow(full_TC), 4], ylab = "Temporal source 4", pch = 1, type = "line")
plot(full_TC[1:nrow(full_TC), 5], ylab = "Temporal source 5", pch = 1, type = "line")
plot(full_TC[1:nrow(full_TC), 6], ylab = "Temporal source 6", pch = 1, type = "line")

# Still need to answer why not norm instead of standardize
# TC won't have same effect?!
# Online says standardise if we know dist - gauss
# If we normalise, the values of TC will be same where as standardised values 
# Are not the same inter TC
# Also creates 0 values still
```

```{r}
# 1b

correlation = cor(full_TC)
corrplot.mixed(correlation, tl.srt = 0)


#col1 = colorRampPalette(c('#7F0000', 'red', '#FF7F00', 'yellow', 'white',
                           'cyan', '#007FFF', 'blue', '#00007F'))
#corrplot(randcorr(6), tl.srt = 0, method = 'color', sig.level = 0.01, col = col1(10))

# Comment on if on TC correlation or not
# 4/5, 5/6 highly correlated as size of circle is size of correlation and relatively positvely correlated
```

```{r}
# 1c
create_tmpSM = function(vert_start,vert_end, horo_start, horo_end) {
  tmpSM = matrix(0, 21, 21)
  tmpSM[vert_start:vert_end, horo_start:horo_end] = 1
  return(tmpSM)
}
```


```{r}
# 1c
tmpSM1 = create_tmpSM(2, 6, 2, 6)
tmpSM2 = create_tmpSM(2, 6, 15, 19)
tmpSM3 = create_tmpSM(8, 13, 2, 6)
tmpSM4 = create_tmpSM(8, 13, 15, 19)
tmpSM5 = create_tmpSM(15, 19, 2, 6)
tmpSM6 = create_tmpSM(15, 19, 15, 19)
```

```{r}
create_df = function(vert_start,vert_end, horo_start, horo_end) {
  df1 = expand.grid(seq_len(21), seq_len(21))
  tmp = matrix(0,21,21)
  tmp[vert_start:vert_end, horo_start:horo_end] = 1
  column = as.vector(tmp)
  df1$data = (column)
  return(df1)
}

plot1 = create_df(2, 6, 2, 6)
plot2 = create_df(2, 6, 15, 19)
plot3 = create_df(8, 13, 2, 6)
plot4 = create_df(8, 13, 15, 19)
plot5 = create_df(15, 19, 2, 6)
plot6 = create_df(15, 19, 15, 19)

ggplot(plot1, aes(Var1, Var2, fill= data)) + 
  geom_tile() + scale_fill_gradient(low="blue", high="red") +
  theme_ipsum()

ggplot(plot2, aes(Var1, Var2, fill= data)) + 
  geom_tile() + scale_fill_gradient(low="blue", high="red") +
  theme_ipsum()

ggplot(plot3, aes(Var1, Var2, fill= data)) + 
  geom_tile() + scale_fill_gradient(low="blue", high="red") +
  theme_ipsum()

ggplot(plot4, aes(Var1, Var2, fill= data)) + 
  geom_tile() + scale_fill_gradient(low="blue", high="red") +
  theme_ipsum()

ggplot(plot5, aes(Var1, Var2, fill= data)) + 
  geom_tile() + scale_fill_gradient(low="blue", high="red") +
  theme_ipsum()

ggplot(plot6, aes(Var1, Var2, fill= data)) + 
  geom_tile() + scale_fill_gradient(low="blue", high="red") +
  theme_ipsum()

```
```{r}
# 1c
tmpSM1 = matrix(tmpSM1, 1, 441)
tmpSM2 = matrix(tmpSM2, 1, 441)
tmpSM3 = matrix(tmpSM3, 1, 441)
tmpSM4 = matrix(tmpSM4, 1, 441)
tmpSM5 = matrix(tmpSM5, 1, 441)
tmpSM6 = matrix(tmpSM6, 1, 441)
tmpSM = matrix(c(tmpSM1, tmpSM2, tmpSM3, tmpSM4, tmpSM5, tmpSM6), 441, 6)
tmpSM = t(tmpSM)

correlation2 = cor(t(tmpSM))
corrplot.mixed(correlation2, upper = "number")
correlation2
# Are theres SM all independent? - yes as not correlated
# Why standardisation not important - If we are looking to replicate it then 
# We still just have two main areas - zero and non zero so the scale of non 0
# Doesn't matter as much
```


```{r}
#1d
noise_t = rnorm(6 * 240, mean = 0, sd = sqrt(0.25))
noise_s = rnorm(6 * 441, mean = 0, sd = sqrt(0.15))

noise_s = matrix(noise_s, 6, 441)
noise_t = matrix(noise_t, 240, 6)

correlation3 = cor(noise_t)
corrplot(correlation3, tl.srt = 0)


correlation4 = cor(t(noise_s))
corrplot(correlation4, tl.srt = 0)
# Check if these two above are correlated
# Highest is like abs(0.12,0.15) so not really that strongly correlated


hist(noise_s)
hist(noise_t)

# Both are equal to 1 even with formula variance = 1.96sd, noise_s = 0.945 so pre close, noise_t slight less 0.936 makes sense with graph
#length(noise_s[(0 - 2*sqrt(0.15) <= noise_s) & (noise_s <= 0 + 2*sqrt(0.15))]) / length(noise_s)
#length(noise_t[(0 - 2*sqrt(0.25) <= noise_t) & (noise_t <= 0 + 2*sqrt(0.25))]) / length(noise_t)

# noise s looks way more normally distributed, while t looks kinda skewed.
# do conf int to normal dist
# Check whether fills var of 1.96*sd (0.95 data)

correlation5 = cor(noise_t %*% noise_s)
#corrplot(correlation5, tl.srt = 0)
correlation5[1:10, 1:10]
# Definitely some correlation eg higher covariance values such as 0.7
# Check if correlated across 441
```
```{r}
#1e

#Can full_tc%*% noise_S and vice versa exist and what happens to them as if we keep we cannot fit model?
X = (full_TC + noise_t) %*% (tmpSM + noise_s)
scaled_X = scale(X)

# Plot graph of sample Time series
set.seed(1)
mysample <- sample(nrow(X), 100)
mysample
sample = X[mysample,1:ncol(X)]
plot(sample[1, 1:ncol(X)], type = "line")
line(sample[2, 1:ncol(X)])




# What info does the plot of vars give
dogy = colVars(X)
plot(dogy)



```


```{r}
#2a
A_LSR = solve(t(full_TC) %*% full_TC) %*% t(full_TC) %*% scaled_X
D_LSR = scaled_X%*% t(A_LSR)

#  Plot and heatmap together
plot(D_LSR[1:nrow(D_LSR),1], type = "line")

# produce legend for heatmap
heatmap(matrix(A[1,1:ncol(A_LSR)], 21, 21), ncol, Colv = NA, Rowv = NA, scale="column")


# WHy linear relo bet 3rd col d_lsr and 30th of X
# Secondly if you look at the slice number 3 build up by third SM. Now read this 3rd SM column-wise, you will find that 30th (2nd column 9th row =30th pixel) pixel position was filled by this 3rd SM and therefore third TC is the only time course that constructs 30th column of X and this is the TC that you retrieve in 3rd Dlsr. There might be some variance in the scatter plot but you will be able to capture visually the linear trend between 3rd Dlsr and 30th X.
#linear relo - 
plot(D_LSR[1:nrow(D_LSR), 3], scaled_X[1:nrow(scaled_X), 30], xlab = "3rd column of D(LSR)", ylab = "30th column of scaled X")

# No linear relo
plot(D_LSR[1:nrow(D_LSR), 4], scaled_X[1:nrow(scaled_X), 30], xlab = "3rd column of D(LSR)", ylab = "30th column of scaled X")
```
```{r}
# Gets the sum of the maximum absolute values in the correlation matrix
max_abs_corr_sum = function(mat1, mat2) {
  corre_mat = cor(mat1, mat2)
  c = get_max_correlations(corre_mat)
  return(sum(c))
}

# Returns the values of the maximum absolute values for each row
get_max_correlations = function(cor_mat) {
  c_var = c(rep(0,6))
  abs_mat = abs(cor_mat)
  cols = max.col(abs_mat)
  
  for (i in 1:6) {
    c_var[i] = cor_mat[i, cols[i]]
  }
  return(c_var)
}
```


```{r}
#2b
lowest_total = 1000000000
ideal_lamda = 0
V = 441
MSE = matrix(0, 1, 2)
for (num in seq(from = 0, to = 1, by = 0.01)) {
  lamda = num
  lamda_hat = lamda * V
  A_RR = solve(t(full_TC) %*% full_TC + diag(nrow(t(full_TC))) * lamda_hat) %*% t(full_TC) %*% scaled_X
  mse = (sum(scaled_X - full_TC %*% A_RR))^2 + lamda_hat * sum(A_RR^2)
  MSE = rbind(MSE, c(lamda, mse))
}

plot(MSE[2:nrow(MSE), 1], MSE[2:nrow(MSE), 2])
min(MSE[2:nrow(MSE), 2])

# Need to find a way to choose the best lamda val
cv <- cv.glmnet(as.matrix(full_TC), as.matrix(scaled_X), alpha = 0)
#

D_RR = scaled_X%*% t(A_RR)
RR_corr = cor(D_RR, full_TC)
LSR_corr = cor(D_LSR, full_TC)

# Upon inspection, largest aboslute correlations are the diagonal values
max.col(abs(RR_corr))
max.col(abs(LSR_corr))


c_tlsr = max_abs_corr_sum(full_TC, D_LSR)
c_trr = max_abs_corr_sum(full_TC, D_RR)


c_trr - c_tlsr

lamda = 1000
lamda_hat = lamda * V
A_1000 = solve(t(full_TC) %*% full_TC + diag(nrow(t(full_TC))) * lamda_hat) %*% t(full_TC) %*% scaled_X


# As A_LSR decrease, A_RR values decrease. But not exactly that close to 0 as some -0.32
plot(A_1000[1:nrow(A_1000), 1], A_LSR[1:nrow(A_LSR), 1], xlab = "A_RR", ylab = "A_LSR")

```
```{r}
create_noise_matrix = function(seed) {
  set.seed(seed = seed)
  noise_t = rnorm(6 * 240, mean = 0, sd = sqrt(0.25))
  noise_s = rnorm(6 * 441, mean = 0, sd = sqrt(0.15))

  noise_s = matrix(noise_s, 6, 441)
  noise_t = matrix(noise_t, 240, 6)
  
  X = (full_TC + noise_t) %*% (tmpSM + noise_s)
  new_X = scale(X)
  return(new_X)
}
noise_1 = create_noise_matrix(30035)
noise_2 = create_noise_matrix(30037)
noise_3 = create_noise_matrix(30038)
noise_4 = create_noise_matrix(30036)
noise_5 = create_noise_matrix(30039)
noise_6 = create_noise_matrix(30040)
noise_7 = create_noise_matrix(30041)
noise_8 = create_noise_matrix(30042)
noise_9 = create_noise_matrix(30043)
noise_10 = create_noise_matrix(30044)


noise_df = list(noise_1, noise_9, noise_8, noise_7, noise_6, noise_5,
                noise_2, noise_3, noise_4, noise_10
                )
#for(mat in noise_df) {
#  print(mat[1:5, 1:3]
#}


```

```{r}
#2c
LR_MSE = matrix(NA, 21, 10)
N = 240
x1 = 21
x2 = 21
nsrcs = 6
V = x1 * x2
i = 1
j = 1
step <- 1/(norm(full_TC %*% t(full_TC)) * 1.1)

for (num in seq(0,1,0.05)) {
  for (x_rep in noise_df) {
    thr <- num*N*step
    Ao <- matrix(0, nsrcs, 1)
    A <- matrix(0, nsrcs, 1)
    Alr <- matrix(0, nsrcs, x1*x2)
    for (k in 1:(x1*x2)) {
      A <- Ao+step*(t(full_TC) %*% (x_rep[,k]-(full_TC%*%Ao)))
      A <- (1/(1+thr)) * (sign(A)*pmax(replicate(nsrcs, 0), abs(A)-thr))
      
      for (rep in 1:10) {
        Ao <- A
        A <- Ao+step * (t(full_TC)%*%(x_rep[,k]-(full_TC%*%Ao)))
        A <- (1/(1+thr)) * (sign(A)*pmax(replicate(nsrcs, 0), abs(A)-thr))
      }
      
      Alr[,k] <- A
    }
    Dlr = x_rep %*% t(Alr)
    LR_MSE[i,j] = sum(sum((x_rep-Dlr%*%Alr)^2)) / (N*V)
    j = j + 1
  }
  j = 1
  i = i + 1
}

LR_avgs = rowMeans(LR_MSE)
plot(LR_avgs)
# Min value is 0.580 when p = 0.55, at same value it diverges

# Since first index is at 0, we want the 12th value between 0 and 1 which is 0.6 
# So we need to index the 13th value
index = which.min(LR_avgs)
rho = (index - 1) * 0.05
```

```{r}
# 2d

thr <- rho*N*step
Ao <- matrix(0, nsrcs, 1)
A <- matrix(0, nsrcs, 1)
Alr <- matrix(0, nsrcs, x1*x2)
for (k in 1:(x1*x2)) {
  A <- Ao+step*(t(full_TC) %*% (scaled_X[,k]-(full_TC%*%Ao)))
  A <- (1/(1+thr)) * (sign(A)*pmax(replicate(nsrcs, 0), abs(A)-thr))
  
  for (rep in 1:10) {
    Ao <- A
    A <- Ao+step * (t(full_TC)%*%(scaled_X[,k]-(full_TC%*%Ao)))
    A <- (1/(1+thr)) * (sign(A)*pmax(replicate(nsrcs, 0), abs(A)-thr))
  }
  
  Alr[,k] <- A
}
Dlr = scaled_X %*% t(Alr)
```

```{r}
ctrr = max_abs_corr_sum(full_TC, D_RR)
csrr = max_abs_corr_sum(t(tmpSM), t(A_RR))
ctlr = max_abs_corr_sum(full_TC, Dlr)
cslr= max_abs_corr_sum(t(tmpSM), t(Alr))

# Both are true
ctlr - ctrr
cslr - csrr
```
```{r}
plot(D_RR, A_RR)
line(Dlr, Alr)
```

```{r}
c_tlsr = 5.658869
c_trr = 5.662374

v = c(rep(0,6))
v[2] = 10
sum(v)
cols = max.col(ctrr_corr)
```


