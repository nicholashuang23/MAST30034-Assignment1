---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 
```{r}
install.packages("corrplot")
library(corrplot)
install.packages("Rfast")
library(Rfast)
install.packages("phyloseq")
install.packages("glmnet")
library(glmnet)
install.packages("randcorr")
library(randcorr)
```


```{r}
# 1a
create_TC = function(interval, one_time, start_time){
  
  # Create initial matrix
  TC = matrix(0, 240, 1)
  
  # Counts for how many ones have been added / not added
  on_count = 1
  off_count = 0
  
  for(i in 1:240){
    
    # Check if the current time in source is before our start time
    if (i <= start_time) {
      next
    }
    
    # Change value in matrix if it is within the time period to do so 
    # Otherwise increment the time that one has not been added
    # Reset if at the end of a interval
    if(on_count <= one_time) {
      TC[i] = 1
      on_count = on_count + 1
    } else{
      off_count = off_count + 1
      if (off_count == interval - one_time) {
        on_count = 1
        off_count = 0
      }
  
    }
  
  }
  return(TC)
}
```


```{r}
# 1a
TC1 = create_TC(30, 15, 0)
TC2 = create_TC(45, 20, 20)
TC3 = create_TC(60, 25, 0)
TC4 = create_TC(40, 15, 0)
TC5 = create_TC(40, 20, 0)
TC6 = create_TC(40, 25, 0)

```

```{r}
# 1a
#standardise_TC = function(TC) {
#  TC_mean = mean(TC)
#  TC_var = var(TC)
#  TC1 = TC - TC_mean
#  TC2 = TC1 / sqrt(TC_var[1])
#  return(TC2)
#}
```





Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```{r}
# 1a
standard_TC1 = scale(TC1)
standard_TC2 = scale(TC2)
standard_TC3 = scale(TC3)
standard_TC4 = scale(TC4)
standard_TC5 = scale(TC5)
standard_TC6 = scale(TC6)
full_TC = matrix(c(standard_TC1, standard_TC2, standard_TC3, standard_TC4, standard_TC5, standard_TC6), 240, 6)
#full_TC2 = matrix(c(TC1, TC2, TC3, TC4, TC5, TC6), 240, 6)
#full_TC2 = scale(full_TC)



```


```{r}
plot(full_TC[1:nrow(full_TC), 1], ylab = "Temporal source 1", pch = 1, type = "line")
plot(full_TC[1:nrow(full_TC), 2], ylab = "Temporal source 2", pch = 1, type = "line")
plot(full_TC[1:nrow(full_TC), 3], ylab = "Temporal source 3", pch = 1, type = "line")
plot(full_TC[1:nrow(full_TC), 4], ylab = "Temporal source 4", pch = 1, type = "line")
plot(full_TC[1:nrow(full_TC), 5], ylab = "Temporal source 5", pch = 1, type = "line")
plot(full_TC[1:nrow(full_TC), 6], ylab = "Temporal source 6", pch = 1, type = "line")

# Still need to answer why not norm instead of standardize
```

```{r}
# 1b

correlation = cor(full_TC)
corrplot.mixed(correlation, tl.srt = 0)


#col1 = colorRampPalette(c('#7F0000', 'red', '#FF7F00', 'yellow', 'white',
                           'cyan', '#007FFF', 'blue', '#00007F'))
#corrplot(randcorr(6), tl.srt = 0, method = 'color', sig.level = 0.01, col = col1(10))

# Comment on if on TC correlation or not
# 4/5, 5/6 highly correlated as size of circle is size of correlation and relatively positvely correlated
```

```{r}
# 1c
create_tmpSM = function(vert_start,vert_end, horo_start, horo_end) {
  tmpSM = matrix(0, 21, 21)
  tmpSM[vert_start:vert_end, horo_start:horo_end] = 1
  return(tmpSM)
  #comment
}
```


```{r}
# 1c
tmpSM1 = create_tmpSM(2, 6, 2, 6)
tmpSM2 = create_tmpSM(2, 6, 15, 19)
tmpSM3 = create_tmpSM(8, 13, 2, 6)
tmpSM4 = create_tmpSM(8, 13, 15, 19)
tmpSM5 = create_tmpSM(15, 19, 2, 6)
tmpSM6 = create_tmpSM(15, 19, 15, 19)
```

```{r}
create_df = function(vert_start,vert_end, horo_start, horo_end) {
  df1 = expand.grid(seq_len(21), seq_len(21))
  tmp = matrix(0,21,21)
  tmp[vert_start:vert_end, horo_start:horo_end] = 1
  column = as.vector(tmp)
  df1$data = (column)
  return(df1)
}
plot1 = create_df(2, 6, 2, 6)
plot2 = create_df(2, 6, 15, 19)
plot3 = create_df(8, 13, 2, 6)
plot4 = create_df(8, 13, 15, 19)
plot5 = create_df(15, 19, 2, 6)
plot6 = create_df(15, 19, 15, 19)

ggplot(plot1, aes(Var1, Var2, fill= data)) + 
  geom_tile()

ggplot(plot2, aes(Var1, Var2, fill= data)) + 
  geom_tile()
ggplot(plot3, aes(Var1, Var2, fill= data)) + 
  geom_tile()
ggplot(plot4, aes(Var1, Var2, fill= data)) + 
  geom_tile()
ggplot(plot5, aes(Var1, Var2, fill= data)) + 
  geom_tile()
ggplot(plot6, aes(Var1, Var2, fill= data)) + 
  geom_tile()


```


```{r}
library(ggplot2)
# 1c
as.data.frame(tmpSM1)
ggplot(tmpSM1) + geom_tile()


#plot(tmpSM3)
#plot(tmpSM4)
#plot(tmpSM5)
#plot(tmpSM6)
```
```{r}
qwe <- LETTERS[1:20]
qwer <- paste0("var", seq(1,20))
data <- expand.grid(X=qwe, Y=qwer)
data$Z <- runif(400, 0, 5)
```


```{r}
# 1c
tmpSM1 = matrix(tmpSM1, 1, 441)
tmpSM1 = matrix(tmpSM2, 1, 441)
tmpSM1 = matrix(tmpSM3, 1, 441)
tmpSM1 = matrix(tmpSM4, 1, 441)
tmpSM1 = matrix(tmpSM5, 1, 441)
tmpSM1 = matrix(tmpSM6, 1, 441)
tmpSM = matrix(c(tmpSM1, tmpSM2, tmpSM3, tmpSM4, tmpSM5, tmpSM6), 441, 6)
tmpSM = t(tmpSM)

correlation2 = cor(t(tmpSM))
corrplot(correlation2, tl.srt = 0)
correlation2
# Are theres SM all independent? Why standardisation not important - imagine one slice is 5 pixels and another 1pixel
```


```{r}
#1d
noise_t = rnorm(6 * 240, mean = 0, sd = 0.25)
noise_s = rnorm(6 * 441, mean = 0, sd = 0.15)

noise_s = matrix(noise_t, 6, 441)
noise_t = matrix(noise_s, 240, 6)

correlation3 = cor(noise_t)
corrplot(correlation3, tl.srt = 0)


correlation4 = cor(t(noise_s))
corrplot(correlation4, tl.srt = 0)
# Check if these two above are correlated


hist(noise_s)
hist(noise_t)
# Check whether fills var of 1.96*sd (0.95 data)

correlation5 = cor(noise_t %*% noise_s)
corrplot(correlation5, tl.srt = 0)
# Check if correlated across 441
```


```{r}
x <- LETTERS[1:20]
y <- paste0("var", seq(1,20))
data <- expand.grid(X=x, Y=y)
data$Z <- runif(400, 0, 5)

x
y
data

ggplot(data, aes(X, Y, fill= Z)) + 
  geom_tile()

t
```
```{r}
#1e

#Can full_tc%*% noise_S and vice versa exist and what happens to them as if we keep we cannot fit model?
X = (full_TC + noise_t) %*% (tmpSM + noise_s)


# Plot graph of sample Time series
set.seed(1)
mysample <- sample(nrow(X), 100)
mysample
plot(sample, type = "line")
sample = X[mysample,1:ncol(X)]
str(sample)



# What info does the plot of vars give
dogy = colVars(X)
plot(dogy)
scaled_X = scale(X)
```


```{r}
#2a
A_LSR = solve(t(full_TC) %*% full_TC) %*% t(full_TC) %*% scaled_X
D_LSR = scaled_X%*% t(A_LSR)

#  Plot and heatmap together
plot(D_LSR[1:nrow(D_LSR),1], type = "line")

# produce legend for heatmap
heatmap(matrix(A[1,1:ncol(A_LSR)], 21, 21), ncol, Colv = NA, Rowv = NA, scale="column")


# WHy linear relo bet 3rd col d_lsr and 30th of X
#linear relo - 
plot(D_LSR[1:nrow(D_LSR), 3], scaled_X[1:nrow(scaled_X), 30], xlab = "3rd column of D(LSR)", ylab = "30th column of scaled X")

# No linear relo
plot(D_LSR[1:nrow(D_LSR), 4], scaled_X[1:nrow(scaled_X), 30], xlab = "3rd column of D(LSR)", ylab = "30th column of scaled X")
```


```{r}
#2b
lowest_total = 1000000000
ideal_lamda = 0
V = 441
MSE = matrix(0, 1, 2)
for (num in seq(from = 0, to = 1, by = 0.01)) {
  lamda = num
  lamda_hat = lamda * V
  A_RR = solve(t(full_TC) %*% full_TC + diag(nrow(t(full_TC))) * lamda_hat) %*% t(full_TC) %*% scaled_X
  mse = (sum(scaled_X - full_TC %*% A_RR))^2 + lamda_hat * sum(A_RR^2)
  MSE = rbind(MSE, c(lamda, mse))
}

plot(MSE[2:nrow(MSE), 1], MSE[2:nrow(MSE), 2])
min(MSE[2:nrow(MSE), 2])

# Need to find a way to choose the best lamda val
cv <- cv.glmnet(as.matrix(full_TC), as.matrix(scaled_X), alpha = 0)
#




D_RR = scaled_X%*% t(A_RR)
RR_corr = cor(D_RR, full_TC)
LSR_corr = cor(D_LSR, full_TC)

# Upon inspection, largest aboslute correlations are the diagonal values
max.col(RR_corr)
max.col(LSR_corr)
c_tlsr = sum(abs(diag(LSR_corr)))
c_trr = sum(abs(diag(RR_corr)))

c_trr - c_tlsr

lamda = 1000
lamda_hat = lamda * V
A_1000 = solve(t(full_TC) %*% full_TC + diag(nrow(t(full_TC))) * lamda_hat) %*% t(full_TC) %*% scaled_X


# As A_LSR decrease, A_RR values decrease. But not exactly that close to 0 as some -0.32
plot(A_1000[1:nrow(A_1000), 1], A_LSR[1:nrow(A_LSR), 1], xlab = "A_RR", ylab = "A_LSR")

```
```{r}
#2c
rho = 0.5
N = 240
x1 = 21
x2 = 21
nsrcs = 6
step <- 1/(norm(full_TC %*% t(full_TC)) * 1.1)
thr <- rho*N*step
Ao <- matrix(0, nsrcs, 1)
A <- matrix(0, nsrcs, 1)
Alr <- matrix(0, nsrcs, x1*x2)

for (k in 1:(x1*x2)) {
  A <- Ao+step*(t(full_TC) %*% (X[,k]-(full_TC%*%Ao)))
  A <- (1/(1+thr)) * (sign(A)*pmax(replicate(nsrcs, 0), abs(A)-thr))
  
  for (i in 1:10) {
    Ao <- A
    A <- Ao+step * (t(full_TC)%*%(X[,k]-(full_TC%*%Ao)))
    A <- (1/(1+thr)) * (sign(A)*pmax(replicate(nsrcs, 0), abs(A)-thr))
  }
  MSE(kk,rr) = sum(sum((Y=Dlr*Alr).Ë†2))/(N*V)
  Alr[,k] <- A
}
```

```{r}
asdfafaf = matrix(c(1, 2, 3, 4, 6, 2, 7, 1, 8), 3, 3)
asdfafaf
sum(asdfafaf^2)

```


